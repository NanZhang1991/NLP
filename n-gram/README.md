
# Task 1
Run the code
```
pip install -r requirements.txt
python ngram.py
```

# Task 2
The idea is to calculate the top 10 tokens of tfidf for each article

# description
I have finished the "required" items.
Sorry, I have not finished any bonus items, beacuse i don't have more time.
The task 1 output contains two files, global_vocab.json and corpus_with_tokens.json. I only ran a part of the data due to time
On required items, it took a total of half a day, it takes an hour to construct the logical structure, it takes two hours to write the code, the test took half an hour, it takes half an hour to sort the results.