{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn matplotlib tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df):\n",
    "    train_set, x = train_test_split(df, \n",
    "        stratify=df['label'],\n",
    "        test_size=0.1, \n",
    "        random_state=42)\n",
    "    val_set, test_set = train_test_split(x, \n",
    "        stratify=x['label'],\n",
    "        test_size=0.5, \n",
    "        random_state=43)\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1000, 3)\n",
      "TRAIN Dataset: (900, 3)\n",
      "Validation Dataset: (50, 3)\n",
      "TEST Dataset: (50, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>波兰斯基要求撤销诱奸案 拍纪录片披露真相(图)</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>女子不服判决带棺材到法院闹事</td>\n",
       "      <td>社会</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>松下 DMC-GF3电脑展现场限售仅4880元</td>\n",
       "      <td>科技</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>江西08年自考女生首次突破一半</td>\n",
       "      <td>教育</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>德媒披露鲁能引援关键人物 是他力荐德甲亚洲强人</td>\n",
       "      <td>体育</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text label  y\n",
       "173  波兰斯基要求撤销诱奸案 拍纪录片披露真相(图)    娱乐  9\n",
       "270           女子不服判决带棺材到法院闹事    社会  5\n",
       "824  松下 DMC-GF3电脑展现场限售仅4880元    科技  4\n",
       "621          江西08年自考女生首次突破一半    教育  3\n",
       "74   德媒披露鲁能引援关键人物 是他力荐德甲亚洲强人    体育  7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./data/THUCNewsChinese.txt\"\n",
    "# read data\n",
    "df_raw = pd.read_csv(data_path,sep=\"\\t\",header=None,names=[\"text\",\"label\"])[:1000]\n",
    "# transfer label\n",
    "df_label = pd.DataFrame({\"label\":[\"财经\",\"房产\",\"股票\",\"教育\",\"科技\",\"社会\",\"时政\",\"体育\",\"游戏\",\"娱乐\"],\"y\":list(range(10))})\n",
    "df_raw = pd.merge(df_raw,df_label,on=\"label\",how=\"left\")\n",
    "# split data\n",
    "train_data, val_data, test_data = split_dataset(df_raw)\n",
    "print(\"FULL Dataset: {}\".format(df_raw.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"Validation Dataset: {}\".format(val_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDataset(dataSet):\n",
    "    inputs = tokenizer(dataSet['text'].tolist(), max_length=max_length, padding='max_length', truncation=True,\\\n",
    "                   return_tensors='tf')\n",
    "    if 'y' in dataSet.columns:\n",
    "        label_list = dataSet['y'].values.tolist() \n",
    "    else:\n",
    "        label_list = None\n",
    "    result = tf.data.Dataset.from_tensor_slices((dict((k,v) for k, v in inputs.items()), label_list))          \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model_dirs/chinese-bert-wwm-ext'\n",
    "# parameters\n",
    "max_length = 128\n",
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "number_of_epochs = 2\n",
    "num_classes = 10 #\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "# train dataset\n",
    "ds_train_encoded = customDataset(train_data).shuffle(10000).batch(batch_size)\n",
    "# val dataset\n",
    "ds_val_encoded = customDataset(val_data).batch(batch_size)\n",
    "# test dataset\n",
    "ds_test_encoded = customDataset(test_data).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TFBertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\NanZhang1991\\NLP\\sequence_classification\\tf2_bert_ch_MultiClass.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/NanZhang1991/NLP/sequence_classification/tf2_bert_ch_MultiClass.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m TFBertForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(model_path, num_labels\u001b[39m=\u001b[39mnum_classes)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/NanZhang1991/NLP/sequence_classification/tf2_bert_ch_MultiClass.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# optimizer Adam recommended\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/NanZhang1991/NLP/sequence_classification/tf2_bert_ch_MultiClass.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlearning_rate,epsilon\u001b[39m=\u001b[39m\u001b[39m1e-08\u001b[39m, clipnorm\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TFBertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_path, num_labels=num_classes)\n",
    "# optimizer Adam recommended\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,epsilon=1e-08, clipnorm=1)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "# fit model\n",
    "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_val_encoded)\n",
    "# evaluate test_set\n",
    "print(\"# evaluate test_set:\",model.evaluate(ds_test_encoded))\n",
    "## model save\n",
    "model.save_pretrained('./model_dirs/fine_tune_MultiClass_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 19s 30ms/step - loss: 0.3030 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30297088623046875, 0.9333000183105469]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_label(logits):\n",
    "    for i in range(len(logits)):\n",
    "        y = tf.argmax(tf.nn.softmax(logits[i], axis=-1)).numpy()\n",
    "        yield y\n",
    "\n",
    "def validation(epoch):\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    for _, data in enumerate(ds_val_encoded, 0):\n",
    "        inputs = data[0]\n",
    "        targets = data[1]\n",
    "        # outputs = model.predict(dict(inputs))\n",
    "        outputs = model(inputs)       \n",
    "        fin_targets.extend(targets.numpy())\n",
    "        fin_outputs.extend(y_label(outputs.logits))\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.9331\n",
      "recall_score (Micro) = 0.9331\n",
      "recall_score (Macro) = 0.9330999999999999\n",
      "F1 Score (Micro) = 0.9331\n",
      "F1 Score (Macro) = 0.9332044368380819\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(number_of_epochs)\n",
    "accuracy = metrics.accuracy_score(targets, outputs)\n",
    "recall_score_micro = metrics.recall_score(targets, outputs, average='micro')\n",
    "recall_score_macro = metrics.recall_score(targets, outputs, average='macro')\n",
    "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "\n",
    "print(f\"Accuracy Score = {accuracy}\")\n",
    "print(f\"recall_score (Micro) = {recall_score_micro}\")\n",
    "print(f\"recall_score (Macro) = {recall_score_macro}\")\n",
    "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c87b1f44594b67819a704c3c4238e15d055a646151ba29c648f9c587b7431b78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
